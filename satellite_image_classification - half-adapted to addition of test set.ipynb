{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">0. Importing Libraries<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "###import datetime\n",
    "\n",
    "# path and data management\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import sample\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# image manipulation/processing\n",
    "import rioxarray\n",
    "from PIL import Image\n",
    "from IPython.display import Image as ipimage\n",
    "import odc\n",
    "\n",
    "# FROM ISI'S REPO\n",
    "import shutil # High-level file operations\n",
    "import random # to generate random samples\n",
    "\n",
    "# Computer Vision\n",
    "import tensorflow as tf # machine learning and neural networks\n",
    "from tensorflow import keras # deep learning and neural networks\n",
    "from tensorflow.keras import layers # layers for neural networks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # real-time data augmentation\n",
    "# NOT FROM ISI'S REPO\n",
    "\n",
    "# classification\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting session parameters\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">1. Importing Datasets<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style = \"color:dimgray\">Data description:</h3>\n",
    "<font color = = \"dimgray\">The full dataset, consisting of 4 folders representing the 4 categories \"cloudy\", \"desert\", \"green area\" and \"water\", with 1500, 1131, 1500 and 1500 images respectively was retrieved from <a href=\"https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification\">Satellite Image Classification</a>.<font>\n",
    "\n",
    "<h3 style = \"color:dimgray\">Goal:</h3>\n",
    "<font color = = \"dimgray\">The use of maching learning algorithm(s) for the classification of the images in the abovementioned categories.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data paths. Note that all the files were initially in the same folders per category and since most of them will \n",
    "# be used for training the model, they were saved the \"train\" folder. Later on they will be sampled to create the test sets\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "cloudy_train = os.path.join(data_path, \"train/cloudy\")\n",
    "desert_train = os.path.join(data_path, \"train/desert\")\n",
    "greenery_train = os.path.join(data_path, \"train/green_area\")\n",
    "water_train = os.path.join(data_path, \"train/water\")\n",
    "\n",
    "# defining directories to be created\n",
    "cloudy_test = os.path.join(data_path, \"test/cloudy\")\n",
    "desert_test = os.path.join(data_path, \"test/desert\")\n",
    "greenery_test = os.path.join(data_path, \"test/green_area\")\n",
    "water_test = os.path.join(data_path, \"test/water\")\n",
    "\n",
    "# listing image names\n",
    "cloudy_img_lst = os.listdir(\"data/train/cloudy\")\n",
    "desert_img_lst = os.listdir(\"data/train/desert\")\n",
    "greenery_img_lst = os.listdir(\"data/train/green_area\")\n",
    "water_img_lst = os.listdir(\"data/train/water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM ISI - creating new directories and ### Making sure new directories do not overwrite previous ones ~ Sabina awesomeness\n",
    "def still_test_dir():\n",
    "    os.makedirs(cloudy_test, exist_ok=True)\n",
    "    os.makedirs(desert_test, exist_ok=True)\n",
    "    os.makedirs(greenery_test, exist_ok=True)\n",
    "    os.makedirs(water_test, exist_ok=True)\n",
    "\n",
    "still_test_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">2. Data Cleaning<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloudy image title check: ['train_35499.jpg', 'train_30389.jpg', 'train_18768.jpg', 'train_29201.jpg', 'train_6829.jpg'] \n",
      "\n",
      "Desert image title check: ['desert(563).jpg', 'desert(494).jpg', 'desert(229).jpg', 'desert(219).jpg', 'desert(827).jpg'] \n",
      "\n",
      "Green area title prefix check: ['Forest_466.jpg', 'Forest_1456.jpg', 'Forest_551.jpg', 'Forest_2986.jpg', 'Forest_496.jpg'] \n",
      "\n",
      "Water image title check: ['SeaLake_708.jpg', 'SeaLake_1993.jpg', 'SeaLake_392.jpg', 'SeaLake_2528.jpg', 'SeaLake_1699.jpg']\n"
     ]
    }
   ],
   "source": [
    "# On examination of the folders' contents, it was made clear that the cloudy images all have the prefix \"train\" since the\n",
    "# models will be trained and validated using samples of all images and for the avoidance of confusion, renaming them seems only right\n",
    "print(\"Cloudy image title check:\", sample(cloudy_img_lst, 5), \"\\n\")\n",
    "print(\"Desert image title check:\", sample(desert_img_lst, 5), \"\\n\")\n",
    "print(\"Green area title prefix check:\", sample(greenery_img_lst, 5), \"\\n\")\n",
    "print(\"Water image title check:\", sample(water_img_lst, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train 1500\n",
      "num cloudy 0\n"
     ]
    }
   ],
   "source": [
    "# double-checking\n",
    "pattern1 = r\"train_(\\d+)\"  # pattern provided by ChatGPT\n",
    "pattern2 = r\"cloudy_(\\d+)\"\n",
    "num_match1 = 0\n",
    "num_match2 = 0\n",
    "\n",
    "# iterating\n",
    "for filename in cloudy_img_lst:\n",
    "    match1 = re.match(pattern1, random.choice(cloudy_img_lst))\n",
    "    match2 = re.match(pattern2, random.choice(cloudy_img_lst))\n",
    "    if match1:\n",
    "        num_match1 += 1\n",
    "    elif match2:\n",
    "        num_match2 += 1\n",
    "    else:\n",
    "        print(\"no match\", filename)\n",
    "\n",
    "print(\"num train\", num_match1)\n",
    "print(\"num cloudy\", num_match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloudy image title check: ['cloudy_25747.jpg', 'cloudy_15278.jpg', 'cloudy_33758.jpg', 'cloudy_18444.jpg', 'cloudy_20554.jpg'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# finally changing names of files in direcrory\n",
    "for filename in cloudy_img_lst:\n",
    "    match = re.match(pattern1, filename)\n",
    "    if match:\n",
    "        num = match.group(1)  # keeping number part intact\n",
    "        new_filename = f\"cloudy_{num}.jpg\"  # defining new filename\n",
    "        os.rename(os.path.join(cloudy_train + \"/\" + filename), (cloudy_train + \"/\" + new_filename))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# redefining cloudy image list with new file names\n",
    "cloudy_img_lst = os.listdir(\"data/train/cloudy\")\n",
    "\n",
    "# double-checking\n",
    "print(\"Cloudy image title check:\", sample(cloudy_img_lst, 5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water image title check: ['water_1366.jpg', 'water_1961.jpg', 'water_1379.jpg', 'water_828.jpg', 'water_1939.jpg'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# also changing the name of \"SeaLake\" images to \"water\" to avoid confusion\n",
    "pattern1 = r\"SeaLake_(\\d+)\"  # pattern provided by ChatGPT\n",
    "\n",
    "for filename in water_img_lst:\n",
    "    match = re.match(pattern1, filename)\n",
    "    if match:\n",
    "        num = match.group(1)  # keeping number part intact\n",
    "        new_filename = f\"water_{num}.jpg\"  # defining new filename\n",
    "        os.rename(os.path.join(water_train + \"/\" + filename), (water_train + \"/\" + new_filename))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# redefining cloudy image list with new file names\n",
    "water_img_lst = os.listdir(\"data/train/water\")\n",
    "\n",
    "# double-checking\n",
    "print(\"Water image title check:\", sample(water_img_lst, 5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_cloudy: 1500\n",
      "count_desert: 1131\n",
      "count_greenery: 1500\n",
      "count_cloudy: 1500 \n",
      "\n",
      "count_all: 5631\n"
     ]
    }
   ],
   "source": [
    "print(\"count_cloudy:\", len(cloudy_img_lst))\n",
    "print(\"count_desert:\", len(desert_img_lst))\n",
    "print(\"count_greenery:\", len(greenery_img_lst))\n",
    "print(\"count_cloudy:\", len(water_img_lst), \"\\n\")\n",
    "print(\"count_all:\", len(cloudy_img_lst + desert_img_lst + greenery_img_lst + water_img_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe with image names and categories\n",
    "image_df = pd.DataFrame(columns = [\"img_name\", \"img_class\"])\n",
    "\n",
    "# list with all image names\n",
    "img_list = cloudy_img_lst + desert_img_lst + greenery_img_lst + water_img_lst\n",
    "\n",
    "# filling out image name column\n",
    "image_df[\"img_name\"] = img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudy_10021.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloudy_10043.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy_10070.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloudy_10081.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cloudy_10096.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>water_995.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>water_996.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>water_997.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>water_998.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>water_999.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_name   class\n",
       "0     cloudy_10021.jpg  cloudy\n",
       "1     cloudy_10043.jpg  cloudy\n",
       "2     cloudy_10070.jpg  cloudy\n",
       "3     cloudy_10081.jpg  cloudy\n",
       "4     cloudy_10096.jpg  cloudy\n",
       "...                ...     ...\n",
       "5587     water_995.jpg   water\n",
       "5588     water_996.jpg   water\n",
       "5589     water_997.jpg   water\n",
       "5590     water_998.jpg   water\n",
       "5591     water_999.jpg   water\n",
       "\n",
       "[5592 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex patterns to fill \"class\" column\n",
    "pattern_cl = r\"^cloudy\"\n",
    "pattern_des = r\"^desert\"\n",
    "pattern_gr = r\"^Forest\"\n",
    "pattern_wa = r\"^water\"\n",
    "\n",
    "# filling out class column\n",
    "for file_name in image_df.img_name:\n",
    "    # match objects or None\n",
    "    match1 = re.search(pattern_cl, str(file_name))\n",
    "    match2 = re.search(pattern_des, str(file_name))\n",
    "    match3 = re.search(pattern_gr, str(file_name))\n",
    "    match4 = re.search(pattern_wa, str(file_name))\n",
    "    if match1:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match1.group(0))\n",
    "    elif match2:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match2.group(0))\n",
    "    elif match3:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match3.group(0))\n",
    "    elif match4:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match4.group(0))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img_name    0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if all rows were filled\n",
    "image_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # taking a closer look into the filenames\n",
    "# for name in image_df.img_name:\n",
    "#     sys.stdout.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">Some of the images in the desert folder seem to be duplicated as pairs like \"desert(1007).jpg\" and \"desert(1007) (1).jpg\" exist. What is more, the filenames of only this folder are written in a different folder<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking visually\n",
    "ipimage(desert_train + \"/\" + \"desert(1007).jpg\", width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipimage(desert_train + \"/\" + \"desert(1007) (1).jpg\", width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The same\n"
     ]
    }
   ],
   "source": [
    "# double-checking with code\n",
    "try:\n",
    "    ipimage(desert_train + \"/\" + \"desert(1007).jpg\", width=200) == ipimage(desert_train + \"/\" + \"desert(1007) (1).jpg\", width=200)\n",
    "except:\n",
    "    print(\"Not the same\")\n",
    "else:\n",
    "    print(\"The same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disposing of spaces in names and standardizing name format\n",
    "pattern_s = r\"\\s\\(\\d+\\)\" # regex writtern with the help of ChatGPT\n",
    "\n",
    "# Dirs to iterate upon\n",
    "list_paths_train = [cloudy_train, desert_train, greenery_train, water_train]\n",
    "\n",
    "# Iterating on each path\n",
    "for the_dir in list_paths_train:\n",
    "    # Iterating for each filename in the dataframe \n",
    "    for filename in image_df.img_name:\n",
    "        # File directory\n",
    "        the_file = the_dir + \"/\" + filename\n",
    "        # Checking first if file directory exists\n",
    "        if os.path.exists(the_file):\n",
    "            # If exists check if pattern matches\n",
    "            match = re.search(pattern_s, filename)\n",
    "            if match:\n",
    "                # Removing image from dir\n",
    "                os.remove(the_file)\n",
    "                # Removing its record from image_df\n",
    "                image_df = image_df.drop(image_df.loc[image_df[\"img_name\"] == filename].index)\n",
    "            elif not match:\n",
    "                # If image is no duplicate, just standardize its name\n",
    "                new_filename = filename.replace(\"(\", \"_\", 1).replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "                os.rename(os.path.join(the_dir + \"/\" + filename), (the_dir + \"/\" + new_filename))\n",
    "        # If path doesn't exist, i.e. file is in different path\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudy_10021.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloudy_10043.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy_10070.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloudy_10081.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cloudy_10096.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>water_995.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>water_996.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>water_997.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>water_998.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>water_999.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_name   class\n",
       "0     cloudy_10021.jpg  cloudy\n",
       "1     cloudy_10043.jpg  cloudy\n",
       "2     cloudy_10070.jpg  cloudy\n",
       "3     cloudy_10081.jpg  cloudy\n",
       "4     cloudy_10096.jpg  cloudy\n",
       "...                ...     ...\n",
       "5587     water_995.jpg   water\n",
       "5588     water_996.jpg   water\n",
       "5589     water_997.jpg   water\n",
       "5590     water_998.jpg   water\n",
       "5591     water_999.jpg   water\n",
       "\n",
       "[5592 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying name standardization to the df\n",
    "for column in image_df.columns:\n",
    "    image_df[column] = image_df[column].apply(lambda x : str(x).replace(\"(\", \"_\", 1).replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "\n",
    "image_df = image_df.reset_index(drop = True)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid repeating all the file operations and directory management for each new session\n",
    "#image_df.to_csv(\"data/image_df.csv\", index=0)\n",
    "image_df = pd.read_csv(\"data/image_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">3. Addressing Data Imbalance<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cloudy    1500\n",
       "forest    1500\n",
       "water     1500\n",
       "desert    1092\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the value counts\n",
    "image_df[\"img_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">The desert class was already under-represented, but after the removal of duplicate images, it  became even more so.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">2 folders will be used. One for the baseline models using the unbalanced data and one for the models using the balanced data.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balanced_df.csv', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Creating path\n",
    "data_balance = os.path.join(os.getcwd(), \"data_balance\")\n",
    "\n",
    "# Copying data\n",
    "dest = shutil.copytree(data_path, data_balance)\n",
    "\n",
    "# Checking that tree has been copied\n",
    "print(os.listdir(data_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining new paths for the image folders\n",
    "cloudy_btrain = os.path.join(data_balance, \"train/cloudy\")\n",
    "desert_btrain = os.path.join(data_balance, \"train/desert\")\n",
    "greenery_btrain = os.path.join(data_balance, \"train/green_area\")\n",
    "water_btrain = os.path.join(data_balance, \"train/water\")\n",
    "\n",
    "# defining directories to be created\n",
    "cloudy_bvalid = os.path.join(data_balance, \"valid/cloudy\")\n",
    "desert_bvalid = os.path.join(data_balance, \"valid/desert\")\n",
    "greenery_bvalid = os.path.join(data_balance, \"valid/green_area\")\n",
    "water_bvalid = os.path.join(data_balance, \"valid/water\")\n",
    "\n",
    "still_test_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the data in this case can easily be done by limiting the number of files to process\n",
    "#  for the over-represented classes to that of the under-represented one\n",
    "# A simple way to do that is to sample the data using the index at our disposal (image_df)\n",
    "sample_cloudy = image_df[image_df[\"img_class\"]==\"cloudy\"].sample(1092)\n",
    "sample_forest = image_df[image_df[\"img_class\"]==\"forest\"].sample(1092)\n",
    "sample_water = image_df[image_df[\"img_class\"]==\"water\"].sample(1092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting the collection together\n",
    "balanced_df = pd.concat([sample_cloudy, sample_forest, sample_water, image_df[image_df[\"img_class\"]==\"desert\"]], axis = 0).sample(frac = 1).reset_index(drop = True)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desert    1092\n",
       "water     1092\n",
       "forest    1092\n",
       "cloudy    1092\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"img_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced_df.to_csv(\"data_balance/balanced_df.csv\", index = 0)\n",
    "balanced_df = pd.read_csv(\"data_balance/balanced_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's tidy up the folders by deleting images not existing in the dataframe\n",
    "dir_bcloudy = os.listdir(cloudy_btrain)\n",
    "dir_bdesert = os.listdir(desert_btrain)\n",
    "dir_bgreen = os.listdir(greenery_btrain)\n",
    "dir_bwater = os.listdir(water_btrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirs to iterate upon\n",
    "paths_list = [cloudy_btrain, desert_btrain, greenery_btrain, water_btrain]\n",
    "folders = [dir_bcloudy, dir_bdesert, dir_bgreen, dir_bwater]\n",
    "\n",
    "# Iterating on each folder dir\n",
    "for i in range(0,len(folders)):\n",
    "    folder = folders[i]\n",
    "    path = paths_list[i]\n",
    "    # Iterating on file in the folder\n",
    "    for folder_filename in folder:\n",
    "        # File directory\n",
    "        the_file = path + \"/\" + folder_filename\n",
    "        # Checking first if file directory exists\n",
    "        if os.path.exists(the_file):\n",
    "            # If exists in list\n",
    "            if folder_filename in balanced_df.img_name.unique().tolist():\n",
    "                # Keep image\n",
    "                continue\n",
    "            else:\n",
    "                os.remove(the_file)\n",
    "        # If path doesn't exist, i.e. file is in different path\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">4. Train-test split<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for moving images\n",
    "def move_img(img_list, source, destination):\n",
    "    for name in img_list:\n",
    "        #if name != '.ipynb_checkpoints':\n",
    "        shutil.move(source + \"/\" + name, destination +  \"/\" + name)\n",
    "        #else:\n",
    "            #continue\n",
    "\n",
    "def copy_img(img_list, source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train-test split\n",
    "#### CAN USE IMPROVEMENTS --> ITERATE ON CLASS_LISTS AND SAMPLES, APPEND THEM TO LIST, SAME FOR TUPLES, ADD PART AND ARGUMENTS THAT CREATE TUPLES IN FUNCTION ####\n",
    "############ EVEN MORE IMPROVEMENTS? --> WRITE FUNCTION THAT PICKS SAMPLE FROM IMAGE FOLDERS, BUT DOESN'T NED TO CREATE NEW DIRECTORIES TO WORK, BUT INSTEAD USES NAMES OF FILES TO ACCESS THEM FOR THE MODEL EACH TIME ###############\n",
    "def homemade_split(df, class_column, name_column, source_dest_tuple_list):\n",
    "    \n",
    "    # list of classes sorted\n",
    "    class_list = df[class_column].unique()\n",
    "    class_list.sort()\n",
    "    \n",
    "    # listing images of the 4 classes\n",
    "    list_class_1 = list(df[df[class_column]==class_list[0]][name_column])\n",
    "    list_class_2 = list(df[df[class_column]==class_list[1]][name_column])\n",
    "    list_class_3 = list(df[df[class_column]==class_list[2]][name_column])\n",
    "    list_class_4 = list(df[df[class_column]==class_list[3]][name_column])\n",
    "    \n",
    "    # Storing random sample of 25% of names of items to be moved in new lists\n",
    "    list_class_1_test_sample = sample(list_class_1, int((len(list_class_1) * .25)))\n",
    "    list_class_2_test_sample = sample(list_class_2, int((len(list_class_2) * .25)))\n",
    "    list_class_3_test_sample = sample(list_class_3, int((len(list_class_3) * .25)))\n",
    "    list_class_4_test_sample = sample(list_class_4, int((len(list_class_4) * .25)))\n",
    "    \n",
    "    # Moving images corresponding to test samples\n",
    "    samples = [list_class_1_test_sample, list_class_2_test_sample, list_class_3_test_sample, list_class_4_test_sample]\n",
    "    \n",
    "    # creating tuples with (sample, source, destination)\n",
    "    tuple_1 = list_class_1_test_sample, source_dest_tuple_list[0][0], source_dest_tuple_list[0][1]\n",
    "    tuple_2 = list_class_2_test_sample, source_dest_tuple_list[1][0], source_dest_tuple_list[1][1]\n",
    "    tuple_3 = list_class_3_test_sample, source_dest_tuple_list[2][0], source_dest_tuple_list[2][1]\n",
    "    tuple_4 = list_class_4_test_sample, source_dest_tuple_list[3][0], source_dest_tuple_list[3][1]\n",
    "    \n",
    "    tuples = [tuple_1, tuple_2, tuple_3, tuple_4]\n",
    "    \n",
    "    for tuple_trio in tuples:\n",
    "        move_img(tuple_trio[0], tuple_trio[1], tuple_trio[2])\n",
    "        \n",
    "\n",
    "    # Merging sample lists\n",
    "    test_list = [*list_class_1_test_sample, *list_class_2_test_sample, *list_class_3_test_sample, *list_class_4_test_sample]\n",
    "\n",
    "    # Creating test_df\n",
    "    test_df = df[df[name_column].isin(test_list)].reset_index(drop=True)\n",
    "\n",
    "    # Creating train_df\n",
    "    train_df = df[~df[\"img_name\"].isin(test_list)].reset_index(drop=True)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cloudy', 'desert', 'forest', 'water'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since the function above is dependent on a sorted list of class names to function correctly, let's see how the sorted list looks like and write our tuples list accordingly\n",
    "class_list = image_df[\"img_class\"].unique()\n",
    "class_list.sort()\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (source, destination) tuples for imbalanced data\n",
    "imb_cl_tuple = cloudy_train, cloudy_valid\n",
    "imb_des_tuple = desert_train, desert_valid\n",
    "imb_gr_tuple = greenery_train, greenery_valid\n",
    "imb_wat_tuple = water_train, water_valid\n",
    "\n",
    "# Tuple list for imbalanced data\n",
    "imbalanced_tuple_list = [imb_cl_tuple, imb_des_tuple, imb_gr_tuple, imb_wat_tuple]\n",
    "\n",
    "# Splitting imbalanced data\n",
    "imbalanced_train, imbalanced_valid = homemade_split(image_df, \"img_class\", \"img_name\", imbalanced_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set: 1398 of which \n",
      "                     375 cloudy \n",
      "                     273 desert \n",
      "                     375 forest \n",
      "                     375 water \n",
      "\n",
      "Length of train set: 4194 of which \n",
      "                     1125 cloudy \n",
      "                      819 desert \n",
      "                     1125 forest \n",
      "                     1125 water\n"
     ]
    }
   ],
   "source": [
    "# indentation trick found at https://stackoverflow.com/questions/18756510/printing-with-indentation-in-python\n",
    "print(\"Length of test set:\", len(imbalanced_test[\"img_class\"]), \"of which\", \"\\n\",\n",
    "      f\"{'':<20}{len(imbalanced_test[imbalanced_test['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<20}{len(imbalanced_test[imbalanced_test['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<20}{len(imbalanced_test[imbalanced_test['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<20}{len(imbalanced_test[imbalanced_test['img_class']=='water'])}\", \"water\", \"\\n\")\n",
    "print(\"Length of train set:\", len(imbalanced_train), \"of which\", \"\\n\",\n",
    "      f\"{'':<20}{len(imbalanced_train[imbalanced_train['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<21}{len(imbalanced_train[imbalanced_train['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<20}{len(imbalanced_train[imbalanced_train['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<20}{len(imbalanced_train[imbalanced_train['img_class']=='water'])}\", \"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file operations are costly timewise and must be precise. saving dfs to csv to avoid having to use listdir with each new session\n",
    "#imbalanced_train.to_csv(\"data/imbalanced_train.csv\", index = 0)\n",
    "#imbalanced_test.to_csv(\"data/imbalanced_test.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_train = pd.read_csv(\"data/imbalanced_train.csv\")\n",
    "imbalanced_test = pd.read_csv(\"data/imbalanced_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cloudy', 'desert', 'forest', 'water'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# better safe than sorry\n",
    "class_list = balanced_df[\"img_class\"].unique()\n",
    "class_list.sort()\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (source, destination) tuples for balanced data\n",
    "bal_cl_tuple = cloudy_btrain, cloudy_btest\n",
    "bal_des_tuple = desert_btrain, desert_btest\n",
    "bal_gr_tuple = greenery_btrain, greenery_btest\n",
    "bal_wat_tuple = water_btrain, water_btest\n",
    "\n",
    "# Tuple list for balanced data\n",
    "balanced_tuple_list = [bal_cl_tuple, bal_des_tuple, bal_gr_tuple, bal_wat_tuple]\n",
    "\n",
    "# Splitting balanced data\n",
    "balanced_train, balanced_test = homemade_split(balanced_df, \"img_class\", \"img_name\", balanced_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # listing images of the 4 classes\n",
    "# cloudy_blist = list(balanced_df[balanced_df[\"img_class\"]==\"cloudy\"][\"img_name\"])\n",
    "# desert_blist = list(balanced_df[balanced_df[\"img_class\"]==\"desert\"][\"img_name\"])\n",
    "# greenery_blist = list(balanced_df[balanced_df[\"img_class\"]==\"forest\"][\"img_name\"])\n",
    "# water_blist = list(balanced_df[balanced_df[\"img_class\"]==\"water\"][\"img_name\"])\n",
    "\n",
    "# # Storing random sample of 25% of names of items to be moved in new lists\n",
    "# cloudy_btest_sample = sample(cloudy_blist, int((len(cloudy_blist) * .25)))\n",
    "# desert_btest_tsample = sample(desert_blist, int((len(desert_blist) * .25)))\n",
    "# greenery_btest_tsample = sample(greenery_blist, int((len(greenery_blist) * .25)))\n",
    "# water_btest_tsample = sample(water_blist, int((len(water_blist) * .25)))\n",
    "\n",
    "# # Moving the images\n",
    "# samples = [cloudy_btest_sample, desert_btest_tsample, greenery_btest_tsample, water_btest_tsample]\n",
    "\n",
    "# move_img(cloudy_btest_sample, cloudy_btrain, cloudy_btest)\n",
    "# move_img(desert_btest_tsample, desert_btrain, desert_btest)\n",
    "# move_img(greenery_btest_tsample, greenery_btrain, greenery_btest)\n",
    "# move_img(water_btest_tsample, water_btrain, water_btest)\n",
    "\n",
    "# # Separating train-test dataframes\n",
    "# test_list = [*cloudy_btest_sample, *desert_btest_tsample, *greenery_btest_tsample, *water_btest_tsample]\n",
    "\n",
    "# # Creating test_df\n",
    "# test_df = balanced_df[balanced_df[\"img_name\"].isin(test_list)].reset_index(drop=True)\n",
    "\n",
    "# # Creating train_df\n",
    "# train_df = balanced_df[~balanced_df[\"img_name\"].isin(test_list)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to access already processed directories of balanced\n",
    "# dir_bcloudy_train = os.listdir(cloudy_btrain)\n",
    "# dir_bdesert_train = os.listdir(desert_btrain)\n",
    "# dir_bgreen_train = os.listdir(greenery_btrain)\n",
    "# dir_bwater_train = os.listdir(water_btrain)\n",
    "\n",
    "# balanced_train_list = [*dir_bcloudy_train, *dir_bdesert_train, *dir_bgreen_train, *dir_bwater_train]\n",
    "\n",
    "# dir_bcloudy_test = os.listdir(cloudy_btest)\n",
    "# dir_bdesert_test = os.listdir(desert_btest)\n",
    "# dir_bgreen_test = os.listdir(greenery_btest)\n",
    "# dir_bwater_test = os.listdir(water_btest)\n",
    "\n",
    "# balanced_test_list = [*dir_bcloudy_test, *dir_bdesert_test, *dir_bgreen_test, *dir_bwater_test]\n",
    "\n",
    "# # # Creating train_df\n",
    "# balanced_train = balanced_df[~balanced_df[\"img_name\"].isin(balanced_train_list)].reset_index(drop=True)\n",
    "\n",
    "# # # Creating test_df\n",
    "# balanced_test = balanced_df[balanced_df[\"img_name\"].isin(balanced_test_list)].reset_index(drop=True)\n",
    "\n",
    "# file operations are costly timewise and must be precise. saving dfs to csv to avoid having to use listdir with each new session\n",
    "# balanced_train.to_csv(\"data_balance/balanced_train.csv\", index = 0)\n",
    "# balanced_test.to_csv(\"data_balance/balanced_test.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test set: 1092 of which \n",
      "                     273 cloudy \n",
      "                     273 desert \n",
      "                     273 forest \n",
      "                     273 water \n",
      "\n",
      "Length of train set: 1092 of which \n",
      "                      273 cloudy \n",
      "                      273 desert \n",
      "                      273 forest \n",
      "                      273 water\n"
     ]
    }
   ],
   "source": [
    "# indentation trick found at https://stackoverflow.com/questions/18756510/printing-with-indentation-in-python\n",
    "print(\"Length of test set:\", len(balanced_test), \"of which\", \"\\n\",\n",
    "      f\"{'':<20}{len(balanced_test[balanced_test['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<20}{len(balanced_test[balanced_test['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<20}{len(balanced_test[balanced_test['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<20}{len(balanced_test[balanced_test['img_class']=='water'])}\", \"water\", \"\\n\")\n",
    "print(\"Length of train set:\", len(balanced_train), \"of which\", \"\\n\",\n",
    "      f\"{'':<21}{len(balanced_train[balanced_train['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<21}{len(balanced_train[balanced_train['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<21}{len(balanced_train[balanced_train['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<21}{len(balanced_train[balanced_train['img_class']=='water'])}\", \"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train = pd.read_csv(\"data_balance/balanced_train.csv\")\n",
    "balanced_test = pd.read_csv(\"data_balance/balanced_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:lightseagreen\">5. Modeling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ISI'S SCRIPT\n",
    "# 🎯 Specific functions\n",
    "def make_model(input_shape): \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (1, 1), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (2, 2), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"color:lightseagreen\">5.1 Image Pre-processing - CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ISI'S SCRIPT\n",
    "# Parameters that we can fine-tune later on\n",
    "img_height = 256   \n",
    "img_width = 256   \n",
    "image_size = (img_height, img_width)\n",
    "batch_size = 128 # using the same as in the tutorial, training utilized in each iteration\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"color:lightseagreen\">5.2.1 Baseline Models: Keras - CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ISI'S\n",
    "# Loading training data\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    train_dir, # training directory\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Loading validation data\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    val_dir, # validation directory\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISI'S\n",
    "# Keras model, build on top of TensorFlow\n",
    "model = make_model(input_shape=image_size + (3,)) # Image size + 3 channels of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING MODEL - ISI'S\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING MODEL - ISI'S\n",
    "epochs = 30\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"data/epochs/save_at_{epoch}.keras\"),\n",
    "]\n",
    "\n",
    "# Train your model without callbacks first\n",
    "hist = model.fit_generator(\n",
    "    train_ds, \n",
    "    epochs=epochs, \n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
