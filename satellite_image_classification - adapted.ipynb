{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">0. Importing Libraries<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "###import datetime\n",
    "\n",
    "# path and data management\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from random import sample\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# image manipulation/processing\n",
    "import rioxarray\n",
    "from PIL import Image\n",
    "from IPython.display import Image as ipimage\n",
    "import odc\n",
    "\n",
    "# FROM ISI'S REPO\n",
    "import shutil # High-level file operations\n",
    "import random # to generate random samples\n",
    "\n",
    "# Computer Vision\n",
    "import tensorflow as tf # machine learning and neural networks\n",
    "from tensorflow import keras # deep learning and neural networks\n",
    "from tensorflow.keras import layers # layers for neural networks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # real-time data augmentation\n",
    "# NOT FROM ISI'S REPO\n",
    "\n",
    "# classification\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting session parameters\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">1. Importing Datasets<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style = \"color:dimgray\">Data description:</h3>\n",
    "<font color = = \"dimgray\">The full dataset, consisting of 4 folders representing the 4 categories \"cloudy\", \"desert\", \"green area\" and \"water\", with 1500, 1131, 1500 and 1500 images respectively was retrieved from <a href=\"https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification\">Satellite Image Classification</a>.<font>\n",
    "\n",
    "<h3 style = \"color:dimgray\">Goal:</h3>\n",
    "<font color = = \"dimgray\">The use of maching learning algorithm(s) for the classification of the images in the abovementioned categories.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data paths. Note that all the files were initially in the same folders per category and since most of them will \n",
    "# be used for training the model, they were saved the \"train\" folder. Later on they will be sampled to create the validation and test sets\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "cloudy_train = os.path.join(data_path, \"train/cloudy\")\n",
    "desert_train = os.path.join(data_path, \"train/desert\")\n",
    "forest_train = os.path.join(data_path, \"train/green_area\")\n",
    "water_train = os.path.join(data_path, \"train/water\")\n",
    "\n",
    "# defining validation directories to be created\n",
    "cloudy_valid = os.path.join(data_path, \"valid/cloudy\")\n",
    "desert_valid = os.path.join(data_path, \"valid/desert\")\n",
    "forest_valid = os.path.join(data_path, \"valid/green_area\")\n",
    "water_valid = os.path.join(data_path, \"valid/water\")\n",
    "\n",
    "# defining test directory to be created\n",
    "imbalanced_test_dir = os.path.join(data_path, \"test/test\")  # prefix imbalanced will make sense later along the script\n",
    "\n",
    "# listing image names\n",
    "cloudy_img_lst = os.listdir(\"data/train/cloudy\")\n",
    "desert_img_lst = os.listdir(\"data/train/desert\")\n",
    "forest_img_lst = os.listdir(\"data/train/green_area\")\n",
    "water_img_lst = os.listdir(\"data/train/water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM ISI and adapted - creating new directories and ### Making sure new directories do not overwrite previous ones ~ Sabina awesomeness\n",
    "def fix_valid_test_dirs(validation_dir_list, test_dir):\n",
    "    # fixing validation directories\n",
    "    for val_dir in validation_dir_list:\n",
    "        os.makedirs(val_dir, exist_ok=True)\n",
    "    # fixing test directory\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "fix_valid_test_dirs([cloudy_valid, desert_valid, forest_valid, water_valid], imbalanced_test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">2. Data Cleaning<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloudy image title check: ['train_20957.jpg', 'train_5925.jpg', 'train_31951.jpg', 'train_4587.jpg', 'train_14787.jpg'] \n",
      "\n",
      "Desert image title check: ['desert(679).jpg', 'desert(195).jpg', 'desert(155).jpg', 'desert(738).jpg', 'desert(671).jpg'] \n",
      "\n",
      "Green area title prefix check: ['Forest_747.jpg', 'Forest_2843.jpg', 'Forest_760.jpg', 'Forest_1672.jpg', 'Forest_2531.jpg'] \n",
      "\n",
      "Water image title check: ['SeaLake_1135.jpg', 'SeaLake_2685.jpg', 'SeaLake_741.jpg', 'SeaLake_1608.jpg', 'SeaLake_1151.jpg']\n"
     ]
    }
   ],
   "source": [
    "# On examination of the folders' contents, it was made clear that the cloudy images all have the prefix \"train\" since the\n",
    "# models will be trained and validated using samples of all images and for the avoidance of confusion, renaming them seems only right\n",
    "print(\"Cloudy image title check:\", sample(cloudy_img_lst, 5), \"\\n\")\n",
    "print(\"Desert image title check:\", sample(desert_img_lst, 5), \"\\n\")\n",
    "print(\"Green area title prefix check:\", sample(forest_img_lst, 5), \"\\n\")\n",
    "print(\"Water image title check:\", sample(water_img_lst, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train 1500\n",
      "num cloudy 0\n"
     ]
    }
   ],
   "source": [
    "# double-checking\n",
    "pattern1 = r\"train_(\\d+)\"  # pattern provided by ChatGPT\n",
    "pattern2 = r\"cloudy_(\\d+)\"\n",
    "num_match1 = 0\n",
    "num_match2 = 0\n",
    "\n",
    "# iterating\n",
    "for filename in cloudy_img_lst:\n",
    "    match1 = re.match(pattern1, random.choice(cloudy_img_lst))\n",
    "    match2 = re.match(pattern2, random.choice(cloudy_img_lst))\n",
    "    if match1:\n",
    "        num_match1 += 1\n",
    "    elif match2:\n",
    "        num_match2 += 1\n",
    "    else:\n",
    "        print(\"no match\", filename)\n",
    "\n",
    "print(\"num train\", num_match1)\n",
    "print(\"num cloudy\", num_match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloudy image title check: ['cloudy_13613.jpg', 'cloudy_30862.jpg', 'cloudy_39830.jpg', 'cloudy_15489.jpg', 'cloudy_13497.jpg'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# finally changing names of files in direcrory\n",
    "for filename in cloudy_img_lst:\n",
    "    match = re.match(pattern1, filename)\n",
    "    if match:\n",
    "        num = match.group(1)  # keeping number part intact\n",
    "        new_filename = f\"cloudy_{num}.jpg\"  # defining new filename\n",
    "        os.rename(os.path.join(cloudy_train + \"/\" + filename), (cloudy_train + \"/\" + new_filename))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# redefining cloudy image list with new file names\n",
    "cloudy_img_lst = os.listdir(\"data/train/cloudy\")\n",
    "\n",
    "# double-checking\n",
    "print(\"Cloudy image title check:\", sample(cloudy_img_lst, 5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water image title check: ['water_1416.jpg', 'water_2320.jpg', 'water_1786.jpg', 'water_2028.jpg', 'water_984.jpg'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# also changing the name of \"SeaLake\" images to \"water\" to avoid confusion\n",
    "pattern1 = r\"SeaLake_(\\d+)\"  # pattern provided by ChatGPT\n",
    "\n",
    "for filename in water_img_lst:\n",
    "    match = re.match(pattern1, filename)\n",
    "    if match:\n",
    "        num = match.group(1)  # keeping number part intact\n",
    "        new_filename = f\"water_{num}.jpg\"  # defining new filename\n",
    "        os.rename(os.path.join(water_train + \"/\" + filename), (water_train + \"/\" + new_filename))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# redefining cloudy image list with new file names\n",
    "water_img_lst = os.listdir(\"data/train/water\")\n",
    "\n",
    "# double-checking\n",
    "print(\"Water image title check:\", sample(water_img_lst, 5), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_cloudy: 1500\n",
      "count_desert: 1131\n",
      "count_water: 1500\n",
      "count_cloudy: 1500 \n",
      "\n",
      "count_all: 5631\n"
     ]
    }
   ],
   "source": [
    "print(\"count_cloudy:\", len(cloudy_img_lst))\n",
    "print(\"count_desert:\", len(desert_img_lst))\n",
    "print(\"count_water:\", len(water_img_lst))\n",
    "print(\"count_cloudy:\", len(water_img_lst), \"\\n\")\n",
    "print(\"count_all:\", len(cloudy_img_lst + desert_img_lst + forest_img_lst + water_img_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe with image names and categories\n",
    "image_df = pd.DataFrame(columns = [\"img_name\", \"img_class\"])\n",
    "\n",
    "# list with all image names\n",
    "img_list = cloudy_img_lst + desert_img_lst + forest_img_lst + water_img_lst\n",
    "\n",
    "# filling out image name column\n",
    "image_df[\"img_name\"] = img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudy_10021.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloudy_10043.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy_10070.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloudy_10081.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cloudy_10096.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>water_995.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>water_996.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>water_997.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>water_998.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>water_999.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5631 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_name img_class\n",
       "0     cloudy_10021.jpg    cloudy\n",
       "1     cloudy_10043.jpg    cloudy\n",
       "2     cloudy_10070.jpg    cloudy\n",
       "3     cloudy_10081.jpg    cloudy\n",
       "4     cloudy_10096.jpg    cloudy\n",
       "...                ...       ...\n",
       "5626     water_995.jpg     water\n",
       "5627     water_996.jpg     water\n",
       "5628     water_997.jpg     water\n",
       "5629     water_998.jpg     water\n",
       "5630     water_999.jpg     water\n",
       "\n",
       "[5631 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex patterns to fill \"class\" column\n",
    "pattern_cl = r\"^cloudy\"\n",
    "pattern_des = r\"^desert\"\n",
    "pattern_gr = r\"^Forest\"\n",
    "pattern_wa = r\"^water\"\n",
    "\n",
    "# filling out class column\n",
    "for file_name in image_df.img_name:\n",
    "    # match objects or None\n",
    "    match1 = re.search(pattern_cl, str(file_name))\n",
    "    match2 = re.search(pattern_des, str(file_name))\n",
    "    match3 = re.search(pattern_gr, str(file_name))\n",
    "    match4 = re.search(pattern_wa, str(file_name))\n",
    "    if match1:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match1.group(0))\n",
    "    elif match2:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match2.group(0))\n",
    "    elif match3:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match3.group(0))\n",
    "    elif match4:\n",
    "        image_df[\"img_class\"].loc[image_df[\"img_name\"]==file_name] = str(match4.group(0))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img_name     0\n",
       "img_class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if all rows were filled\n",
    "image_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # taking a closer look into the filenames\n",
    "# for name in image_df.img_name:\n",
    "#     sys.stdout.write(name + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">Some of the images in the desert folder seem to be duplicated as pairs like \"desert(1007).jpg\" and \"desert(1007) (1).jpg\" exist. What is more, the filenames of only this folder are written in a different folder<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking visually\n",
    "ipimage(desert_train + \"/\" + \"desert(1007).jpg\", width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "image/jpeg": {
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipimage(desert_train + \"/\" + \"desert(1007) (1).jpg\", width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The same\n"
     ]
    }
   ],
   "source": [
    "# double-checking with code\n",
    "try:\n",
    "    ipimage(desert_train + \"/\" + \"desert(1007).jpg\", width=200) == ipimage(desert_train + \"/\" + \"desert(1007) (1).jpg\", width=200)\n",
    "except:\n",
    "    print(\"Not the same\")\n",
    "else:\n",
    "    print(\"The same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disposing of spaces in names and standardizing name format\n",
    "pattern_s = r\"\\s\\(\\d+\\)\" # regex writtern with the help of ChatGPT\n",
    "\n",
    "# Dirs to iterate upon\n",
    "list_paths_train = [cloudy_train, desert_train, forest_train, water_train]\n",
    "\n",
    "# Iterating on each path\n",
    "for the_dir in list_paths_train:\n",
    "    # Iterating for each filename in the dataframe \n",
    "    for filename in image_df.img_name:\n",
    "        # File directory\n",
    "        the_file = the_dir + \"/\" + filename\n",
    "        # Checking first if file directory exists\n",
    "        if os.path.exists(the_file):\n",
    "            # If exists check if pattern matches\n",
    "            match = re.search(pattern_s, filename)\n",
    "            if match:\n",
    "                # Removing image from dir\n",
    "                os.remove(the_file)\n",
    "                # Removing its record from image_df\n",
    "                image_df = image_df.drop(image_df.loc[image_df[\"img_name\"] == filename].index)\n",
    "            elif not match:\n",
    "                # If image is no duplicate, just standardize its name\n",
    "                new_filename = filename.replace(\"(\", \"_\", 1).replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "                os.rename(os.path.join(the_dir + \"/\" + filename), (the_dir + \"/\" + new_filename))\n",
    "        # If path doesn't exist, i.e. file is in different path\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cloudy_17556.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloudy_25127.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy_15562.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water_1147.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water_1788.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>water_2544.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>forest_2208.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589</th>\n",
       "      <td>desert_490.jpg</td>\n",
       "      <td>desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>forest_2058.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>water_261.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_name img_class\n",
       "0     cloudy_17556.jpg    cloudy\n",
       "1     cloudy_25127.jpg    cloudy\n",
       "2     cloudy_15562.jpg    cloudy\n",
       "3       water_1147.jpg     water\n",
       "4       water_1788.jpg     water\n",
       "...                ...       ...\n",
       "5587    water_2544.jpg     water\n",
       "5588   forest_2208.jpg    forest\n",
       "5589    desert_490.jpg    desert\n",
       "5590   forest_2058.jpg    forest\n",
       "5591     water_261.jpg     water\n",
       "\n",
       "[5592 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying name standardization to the df\n",
    "for column in image_df.columns:\n",
    "    image_df[column] = image_df[column].apply(lambda x : str(x).replace(\"(\", \"_\", 1).replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "\n",
    "image_df = image_df.sample(frac = 1).reset_index(drop = True)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum image size: [256, 256]\n",
      "Minimum image size: [64, 64]\n"
     ]
    }
   ],
   "source": [
    "# Before moving on to potential changes in the folders, let's make sure we know the min and max image sizes, in case resizing needs to be performed\n",
    "# Tuple pairs of paths for directories and lists of names per directory. Tuples are highly convenient, as they allow for targeting only specific folders\n",
    "# during iterations, instead of going over all potential directories with conditionals to find out whether they exist or not\n",
    "# Since the names of the files have changed, the lists of files must be adapted accordingly\n",
    "cloudy_img_lst = os.listdir(\"data/train/cloudy\")\n",
    "desert_img_lst = os.listdir(\"data/train/desert\")\n",
    "forest_img_lst = os.listdir(\"data/train/green_area\")\n",
    "water_img_lst = os.listdir(\"data/train/water\")\n",
    "\n",
    "cloudy_siz_tup = cloudy_train, cloudy_img_lst\n",
    "desert_siz_tup = desert_train, desert_img_lst\n",
    "forest_siz_tup = forest_train, forest_img_lst\n",
    "water_siz_tup = water_train, water_img_lst\n",
    "\n",
    "\n",
    "# List to store dimensions of images\n",
    "size_list = []\n",
    "\n",
    "# Iterating on tuple list\n",
    "for pair in [cloudy_siz_tup, desert_siz_tup, forest_siz_tup, water_siz_tup]:\n",
    "    # Iterating on image list\n",
    "    for filename in pair[1]:\n",
    "        # Getting item from path using second item in tuple\n",
    "        img_get = Image.open(pair[0] + \"/\" + filename)\n",
    "        # Storing image size\n",
    "        img_size = img_get.size\n",
    "        size_list.append(img_size)\n",
    "\n",
    "# Storing max and min sizes \n",
    "res_max = list(map(max, zip(*size_list)))\n",
    "res_min = list(map(min, zip(*size_list)))\n",
    "\n",
    "print(\"Maximum image size:\", res_max)\n",
    "print(\"Minimum image size:\", res_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_df.to_csv(\"data/image_df.csv\", index=0)\n",
    "image_df = pd.read_csv(\"data/image_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">3. Addressing Data Imbalance<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cloudy    1500\n",
       "water     1500\n",
       "forest    1500\n",
       "desert    1092\n",
       "Name: img_class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at the value counts\n",
    "image_df[\"img_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">The desert class was already under-represented, but after the removal of duplicate images, it  became even more so.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">2 folders will be used. One for the baseline models using the imbalanced data and one for the models using the balanced data.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating path\n",
    "data_balance = os.path.join(os.getcwd(), \"data_balance\")\n",
    "\n",
    "# Copying data\n",
    "# dest = shutil.copytree(data_path, data_balance)\n",
    "\n",
    "# Checking that tree has been copied\n",
    "# print(os.listdir(data_balance))\n",
    "\n",
    "# image_df.csv was also copied but can easily just be deleted manually which will also be the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining new paths for the image folders\n",
    "cloudy_btrain = os.path.join(data_balance, \"train/cloudy\")\n",
    "desert_btrain = os.path.join(data_balance, \"train/desert\")\n",
    "forest_btrain = os.path.join(data_balance, \"train/green_area\")\n",
    "water_btrain = os.path.join(data_balance, \"train/water\")\n",
    "\n",
    "# defining new validation directories to be created\n",
    "cloudy_bvalid = os.path.join(data_balance, \"valid/cloudy\")\n",
    "desert_bvalid = os.path.join(data_balance, \"valid/desert\")\n",
    "forest_bvalid = os.path.join(data_balance, \"valid/green_area\")\n",
    "water_bvalid = os.path.join(data_balance, \"valid/water\")\n",
    "\n",
    "# defining new test directory to be created\n",
    "balanced_test_dir = os.path.join(data_balance, \"test/test\")\n",
    "\n",
    "# fixing them up so they don't get overwritten\n",
    "fix_valid_test_dirs([cloudy_bvalid, desert_bvalid, forest_bvalid, water_bvalid], balanced_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the data in this case can easily be done by limiting the number of files to process\n",
    "#  for the over-represented classes to that of the under-represented one\n",
    "# A simple way to do that is to sample the data using the index at our disposal (image_df)\n",
    "sample_cloudy = image_df[image_df[\"img_class\"]==\"cloudy\"].sample(1092)\n",
    "sample_forest = image_df[image_df[\"img_class\"]==\"forest\"].sample(1092)\n",
    "sample_water = image_df[image_df[\"img_class\"]==\"water\"].sample(1092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest_963.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water_274.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forest_2307.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forest_892.jpg</td>\n",
       "      <td>forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desert_532.jpg</td>\n",
       "      <td>desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>water_2922.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>desert_476.jpg</td>\n",
       "      <td>desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>water_2897.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>cloudy_1194.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>water_2760.jpg</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             img_name img_class\n",
       "0      forest_963.jpg    forest\n",
       "1       water_274.jpg     water\n",
       "2     forest_2307.jpg    forest\n",
       "3      forest_892.jpg    forest\n",
       "4      desert_532.jpg    desert\n",
       "...               ...       ...\n",
       "4363   water_2922.jpg     water\n",
       "4364   desert_476.jpg    desert\n",
       "4365   water_2897.jpg     water\n",
       "4366  cloudy_1194.jpg    cloudy\n",
       "4367   water_2760.jpg     water\n",
       "\n",
       "[4368 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting the collection together\n",
    "balanced_df = pd.concat([sample_cloudy, sample_forest, sample_water, image_df[image_df[\"img_class\"]==\"desert\"]], axis = 0).sample(frac = 1).reset_index(drop = True)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forest    1092\n",
       "water     1092\n",
       "desert    1092\n",
       "cloudy    1092\n",
       "Name: img_class, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"img_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced_df.to_csv(\"data_balance/balanced_df.csv\", index = 0)\n",
    "balanced_df = pd.read_csv(\"data_balance/balanced_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"dimgray\">First let's tidy up the folders by deleting images not existing in the dataframe.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_bcloudy = os.listdir(cloudy_btrain)\n",
    "dir_bdesert = os.listdir(desert_btrain)\n",
    "dir_bgreen = os.listdir(forest_btrain)\n",
    "dir_bwater = os.listdir(water_btrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirs to iterate on\n",
    "paths_list = [cloudy_btrain, desert_btrain, forest_btrain, water_btrain]\n",
    "folders = [dir_bcloudy, dir_bdesert, dir_bgreen, dir_bwater]\n",
    "\n",
    "# Iterating on each folder dir\n",
    "for i in range(0,len(folders)):\n",
    "    folder = folders[i]\n",
    "    path = paths_list[i]\n",
    "    # Iterating on file in the folder\n",
    "    for folder_filename in folder:\n",
    "        # File directory\n",
    "        the_file = path + \"/\" + folder_filename\n",
    "        # Checking first if file directory exists\n",
    "        if os.path.exists(the_file):\n",
    "            # If exists in list\n",
    "            if folder_filename in balanced_df.img_name.unique().tolist():\n",
    "                # Keep image\n",
    "                continue\n",
    "            else:\n",
    "                os.remove(the_file)\n",
    "        # If path doesn't exist, i.e. file is in different path\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = \"lightseagreen\">4. Train-test split<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample images from the different classes\n",
    "def names_per_class(df, class_column, name_column):\n",
    "    # sorted list of classes\n",
    "    class_list = df[class_column].unique()\n",
    "    class_list.sort()\n",
    "    # list to store lists\n",
    "    nested_class_lists = []\n",
    "    # storing lists in class_nested_lists\n",
    "    for each_class in class_list:\n",
    "        class_images = list(df[df[class_column]==each_class][name_column])\n",
    "        nested_class_lists.append(class_images)\n",
    "    \n",
    "    return nested_class_lists\n",
    "\n",
    "# Function to sample names following names_per_class() function\n",
    "def name_sampler(nested_class_lists, percentage):\n",
    "    # list to store samples\n",
    "    nested_samples = []\n",
    "    for each_list in nested_class_lists:\n",
    "        random.seed(400)\n",
    "        list_class_sample = sample(each_list, int(len(each_list) * percentage))\n",
    "        nested_samples.append(list_class_sample)\n",
    "    \n",
    "    return nested_samples\n",
    "\n",
    "# Function for moving images\n",
    "def move_img(img_list, source, destination):\n",
    "    for name in img_list:\n",
    "        shutil.move(source + \"/\" + name, destination +  \"/\" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train-validation-test split\n",
    "#### CAN USE IMPROVEMENTS --> ITERATE ON CLASS_LISTS AND SAMPLES, APPEND THEM TO LIST, SAME FOR TUPLES, ADD PART AND ARGUMENTS THAT CREATE TUPLES IN FUNCTION ####\n",
    "def homemade_split(df, class_column, name_column, valid_source_dest_tuple_list, test_dest, split_percent=.2): # setting default for overall splitting to validation/test sets to 20%\n",
    "    \n",
    "\n",
    "    # writing image names in lists\n",
    "    nested_lists_fraction_1 = names_per_class(df, class_column, name_column)\n",
    "    \n",
    "    # storing random sample of 25% of names of items in lists to be moved  in validation folder in new lists\n",
    "    name_samples = name_sampler(nested_lists_fraction_1, split_percent)  # further splitting the percentage of data to keep only half of the initial split for validation set\n",
    "    \n",
    "    split_name_list = []\n",
    "    for name_sample in name_samples:\n",
    "        # dividing name lists by 2 for validation and test sets\n",
    "        valid_frac = name_sample[:int(len(name_sample)/2)]\n",
    "        test_frac = name_sample[int(len(name_sample)/2):]\n",
    "        # saving each pair of lists in a tuple for easy access\n",
    "        name_sample_tup = valid_frac, test_frac\n",
    "        # saving the 4 tuples in a new list\n",
    "        split_name_list.append(name_sample_tup)\n",
    "        \n",
    "    # creating lists for validation and test sets by merging the 4 subsets\n",
    "    valid_list_names = [*split_name_list[0][0], *split_name_list[1][0], *split_name_list[2][0], *split_name_list[3][0]]\n",
    "    test_list_names = [*split_name_list[0][1], *split_name_list[1][1], *split_name_list[2][1], *split_name_list[3][1]]\n",
    "    \n",
    "    # deviding split sample by 2 for validation-test sets\n",
    "    df_fraction_valid = df[df[name_column].isin(valid_list_names)]\n",
    "    df_fraction_test = df[df[name_column].isin(test_list_names)]\n",
    "    \n",
    "    # this list will be used to subtract columns from training dataframe\n",
    "    name_sample_mixed = [*name_samples[0], *name_samples[1], *name_samples[2], *name_samples[3]]\n",
    "    \n",
    "    # redefining train_df with remaining rows\n",
    "    train_df = df[~df[name_column].isin(name_sample_mixed)].reset_index(drop=True)\n",
    "    \n",
    "    # writing image names in lists\n",
    "    nested_name_lists_valid = names_per_class(df_fraction_valid, class_column, name_column)\n",
    "\n",
    "    # creating tuples with (sample, source, destination) for validation data\n",
    "    tuple_1 = nested_name_lists_valid[0], valid_source_dest_tuple_list[0][0], valid_source_dest_tuple_list[0][1]\n",
    "    tuple_2 = nested_name_lists_valid[1], valid_source_dest_tuple_list[1][0], valid_source_dest_tuple_list[1][1]\n",
    "    tuple_3 = nested_name_lists_valid[2], valid_source_dest_tuple_list[2][0], valid_source_dest_tuple_list[2][1]\n",
    "    tuple_4 = nested_name_lists_valid[3], valid_source_dest_tuple_list[3][0], valid_source_dest_tuple_list[3][1]\n",
    "    \n",
    "    # putting tuples in a list\n",
    "    tuples = [tuple_1, tuple_2, tuple_3, tuple_4]\n",
    "\n",
    "    # moving to validation dirs\n",
    "    for tuple_trio in tuples:\n",
    "        move_img(tuple_trio[0], tuple_trio[1], tuple_trio[2])\n",
    "\n",
    "\n",
    "    # repeating above steps for test folder\n",
    "    nested_lists_test = names_per_class(df_fraction_test, class_column, name_column)\n",
    "    \n",
    "    # create source path list and name_list list\n",
    "    source_path_list = [valid_source_dest_tuple_list[0][0], valid_source_dest_tuple_list[1][0], valid_source_dest_tuple_list[2][0], valid_source_dest_tuple_list[3][0]]\n",
    "    \n",
    "    # move files of test fraction to test folder\n",
    "    i = 0\n",
    "    for source_path in source_path_list:\n",
    "        move_img(split_name_list[i][1], source_path, test_dest)\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "    return train_df, df_fraction_valid, df_fraction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (source, destination) tuples for imbalanced data\n",
    "imb_cl_tuple = cloudy_train, cloudy_valid\n",
    "imb_des_tuple = desert_train, desert_valid\n",
    "imb_gr_tuple = forest_train, forest_valid\n",
    "imb_wat_tuple = water_train, water_valid\n",
    "\n",
    "# Tuple list for imbalanced validation data\n",
    "imbalanced_tuple_list = [imb_cl_tuple, imb_des_tuple, imb_gr_tuple, imb_wat_tuple]\n",
    "\n",
    "# Splitting imbalanced data\n",
    "imbalanced_train, imbalanced_valid, imbalanced_test = homemade_split(image_df, \"img_class\", \"img_name\", imbalanced_tuple_list, imbalanced_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set:      4474 of which \n",
      "                          1200 cloudy \n",
      "                          874 desert \n",
      "                          1200 forest \n",
      "                          1200 water\n",
      "Length of validation set: 559 of which \n",
      "                          150 cloudy \n",
      "                          109 desert \n",
      "                          150 forest \n",
      "                          150 water \n",
      "\n",
      "Length of test set:       559 mixed\n"
     ]
    }
   ],
   "source": [
    "# indentation trick found at https://stackoverflow.com/questions/18756510/printing-with-indentation-in-python\n",
    "print(\"Length of train set:\", f\"{'':<5}{len(imbalanced_train)}\", \"of which\", \"\\n\",\n",
    "      f\"{'':<25}{len(imbalanced_train[imbalanced_train['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<25}{len(imbalanced_train[imbalanced_train['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<25}{len(imbalanced_train[imbalanced_train['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<25}{len(imbalanced_train[imbalanced_train['img_class']=='water'])}\", \"water\")\n",
    "\n",
    "print(\"Length of validation set:\", len(imbalanced_valid[\"img_class\"]), \"of which\", \"\\n\",\n",
    "      f\"{'':<25}{len(imbalanced_valid[imbalanced_valid['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<25}{len(imbalanced_valid[imbalanced_valid['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<25}{len(imbalanced_valid[imbalanced_valid['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<25}{len(imbalanced_valid[imbalanced_valid['img_class']=='water'])}\", \"water\", \"\\n\")\n",
    "\n",
    "print(\"Length of test set:\", f\"{'':<6}{len(imbalanced_test)}\", \"mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file operations are costly timewise and must be precise. saving dfs to csv to avoid having to use listdir with each new session\n",
    "#imbalanced_train.to_csv(\"data/imbalanced_train.csv\", index = 0)\n",
    "#imbalanced_valid.to_csv(\"data/imbalanced_valid.csv\", index = 0)\n",
    "#imbalanced_test.to_csv(\"data/imbalanced_test.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_train = pd.read_csv(\"data/imbalanced_train.csv\")\n",
    "imbalanced_valid = pd.read_csv(\"data/imbalanced_valid.csv\")\n",
    "imbalanced_test = pd.read_csv(\"data/imbalanced_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (source, destination) tuples for balanced data\n",
    "bal_cl_tuple = cloudy_btrain, cloudy_bvalid\n",
    "bal_des_tuple = desert_btrain, desert_bvalid\n",
    "bal_gr_tuple = forest_btrain, forest_bvalid\n",
    "bal_wat_tuple = water_btrain, water_bvalid\n",
    "\n",
    "# Tuple list for balanced data\n",
    "balanced_tuple_list = [bal_cl_tuple, bal_des_tuple, bal_gr_tuple, bal_wat_tuple]\n",
    "\n",
    "# Splitting balanced data\n",
    "balanced_train, balanced_valid, balanced_test = homemade_split(balanced_df, \"img_class\", \"img_name\", balanced_tuple_list, balanced_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set:      436 of which \n",
      "                          874 cloudy \n",
      "                          874 desert \n",
      "                          874 forest \n",
      "                          874 water\n",
      "Length of validation set: 436 of which \n",
      "                          109 cloudy \n",
      "                          109 desert \n",
      "                          109 forest \n",
      "                          109 water \n",
      "\n",
      "Length of test set:       436 mixed\n"
     ]
    }
   ],
   "source": [
    "# indentation trick found at https://stackoverflow.com/questions/18756510/printing-with-indentation-in-python\n",
    "print(\"Length of train set:\", f\"{'':<5}{len(balanced_test)}\", \"of which\", \"\\n\",\n",
    "      f\"{'':<25}{len(balanced_train[balanced_train['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<25}{len(balanced_train[balanced_train['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<25}{len(balanced_train[balanced_train['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<25}{len(balanced_train[balanced_train['img_class']=='water'])}\", \"water\")\n",
    "\n",
    "print(\"Length of validation set:\", len(balanced_valid), \"of which\", \"\\n\",\n",
    "      f\"{'':<25}{len(balanced_valid[balanced_valid['img_class']=='cloudy'])}\", \"cloudy\", \"\\n\",\n",
    "         f\"{'':<25}{len(balanced_valid[balanced_valid['img_class']=='desert'])}\", \"desert\", \"\\n\", \n",
    "         f\"{'':<25}{len(balanced_valid[balanced_valid['img_class']=='forest'])}\", \"forest\", \"\\n\",\n",
    "         f\"{'':<25}{len(balanced_valid[balanced_valid['img_class']=='water'])}\", \"water\", \"\\n\")\n",
    "\n",
    "print(\"Length of test set:\", f\"{'':<6}{len(balanced_test)}\", \"mixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced_train.to_csv(\"data_balance/balanced_train.csv\")\n",
    "#balanced_valid.to_csv(\"data_balance/balanced_valid.csv\")\n",
    "#balanced_test.to_csv(\"data_balance/balanced_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train = pd.read_csv(\"data_balance/balanced_train.csv\")\n",
    "balanced_valid = pd.read_csv(\"data_balance/balanced_valid.csv\")\n",
    "balanced_test = pd.read_csv(\"data_balance/balanced_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"color:lightseagreen\">5. Modeling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ISI'S SCRIPT\n",
    "# 🎯 Specific functions\n",
    "def make_model(input_shape): \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (1, 1), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (2, 2), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"color:lightseagreen\">5.1 Image Pre-processing - CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ISI'S SCRIPT\n",
    "# Parameters that we can fine-tune later on\n",
    "img_height = 256   \n",
    "img_width = 256   \n",
    "image_size = (img_height, img_width)\n",
    "batch_size = 128 # using the same as in the tutorial, training utilized in each iteration\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"color:lightseagreen\">5.2.1 Baseline Models: Keras - CNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM ISI'S\n",
    "# Loading training data\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    train_dir, # training directory\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Loading validation data\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    val_dir, # validation directory\n",
    "    seed=1337,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISI'S\n",
    "# Keras model, build on top of TensorFlow\n",
    "model = make_model(input_shape=image_size + (3,)) # Image size + 3 channels of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING MODEL - ISI'S\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING MODEL - ISI'S\n",
    "epochs = 30\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"data/epochs/save_at_{epoch}.keras\"),\n",
    "]\n",
    "\n",
    "# Train your model without callbacks first\n",
    "hist = model.fit_generator(\n",
    "    train_ds, \n",
    "    epochs=epochs, \n",
    "    validation_data=val_ds,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
